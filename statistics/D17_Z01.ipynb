{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Najważniejszą rzeczą do zrozumienia jest to, że ten kod w rzeczywistości nie wykonuje żadnych obliczeń, nawet jeśli wygląda na to (szczególnie na ostatniej linii). Po prostu tworzy graf obliczeniowy. \n",
    "\n",
    "W rzeczywistości nawet zmienne nie zostały jeszcze zainicjowane. Aby wykonać ten graf, należy otworzyć sesję TensorFlow i użyć jej do zainicjowania zmiennych i wyliczenia $f$. \n",
    "\n",
    "Sesja TensorFlow zajmuje się umieszczaniem operacji na urządzeniach takich jak procesory i GPU oraz ich uruchomieniem i przechowuje wszystkie wartości zmiennych:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ciągłe powtarzanie sesji **sess.run()** jest nieco uciążliwe, ale na szczęście jest lepszy sposób:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zamiast ręcznie uruchamiać inicjalizator dla każdej zmiennej, można użyć skrótu\n",
    "Funkcja **global_variables_initializer()**. Zauważ, że nie wykonuje on natychmiastowej nitlizacji, lecz tworzy na wykresie węzeł, który inicjalizuje wszystkie zmienne podczas działania:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer() # prepare an init node\n",
    "with tf.Session() as sess:\n",
    "    init.run() # actually initialize all the variables\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program TensorFlow dzieli się zazwyczaj na dwie części: pierwsza część tworzy graf obliczeniowy (nazywa się to fazą konstrukcyjną), a druga część uruchamia go (jest to faza wykonania)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tworzeniw grfów\n",
    "Każdy utworzony węzeł jest automatycznie dodawany do domyślnego grafu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W większości przypadków jest to w porządku, ale czasami możesz chcieć zarządzać wieloma niezależnymi grafami. Możesz to zrobić, tworząc nowy graf i tymczasowo ustawiając go jako domyślny wykres wewnątrz bloku:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W Jupyter (lub w powłoce Pythona) często używa się tych samych poleceń więcej niż raz podczas eksperymentowania. W rezultacie może pojawić się domyślny wykres zawierający wiele zduplikowanych węzłów. Jednym z rozwiązań jest ponowne uruchomienie jądra Jupytera (lub powłoki Pythona), ale wygodniejszym rozwiązaniem jest przywrócenie domyślnego wykresu poprzez uruchomienie **tf.reset_default_graph()**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podczas inicjalizacji węzła TensorFlow automatycznie określa zestaw węzłów, od których zależy i najpierw inicjalizuje te węzły. Rozważmy na przykład następujący kod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval()) \n",
    "    print(z.eval()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weźmy dane housing oraz wykonajmy regresję liniową za pomocą rozwiązania układu równań liniowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20640 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "print(m, n)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "housing_data_scaled=scaler.fit_transform(housing.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za pomocą NumPy wyglądało by to tak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 9)\n"
     ]
    }
   ],
   "source": [
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing_data_scaled]\n",
    "print(housing_data_plus_bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06855817]\n",
      " [ 0.8296193 ]\n",
      " [ 0.11875165]\n",
      " [-0.26552688]\n",
      " [ 0.30569623]\n",
      " [-0.004503  ]\n",
      " [-0.03932627]\n",
      " [-0.89988565]\n",
      " [-0.870541  ]]\n"
     ]
    }
   ],
   "source": [
    "X = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1, 1)\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "print(theta_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Za pomocą Scikit-Learn można to zrobić tak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06855817]\n",
      " [ 0.8296193 ]\n",
      " [ 0.11875165]\n",
      " [-0.26552688]\n",
      " [ 0.30569623]\n",
      " [-0.004503  ]\n",
      " [-0.03932627]\n",
      " [-0.89988565]\n",
      " [-0.870541  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_data_scaled, housing.target.reshape(-1, 1))\n",
    "\n",
    "print(np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tensorflow możemy to zrobić tak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06856298]\n",
      " [ 0.82961965]\n",
      " [ 0.11875178]\n",
      " [-0.26552707]\n",
      " [ 0.30569667]\n",
      " [-0.00450281]\n",
      " [-0.03932635]\n",
      " [-0.8998825 ]\n",
      " [-0.87053877]]\n"
     ]
    }
   ],
   "source": [
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Wykonaj regresje na poniższych danych oraz narysuj wykres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x227e5070160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "data = np.loadtxt(\"life_satisfaction.csv\",\n",
    "                  dtype=np.float32,\n",
    "                  delimiter=\",\",\n",
    "                  skiprows=1,\n",
    "                  usecols=[1, 2])\n",
    "X_train = data[:, 0:1] / 10000 # feature scaling\n",
    "y_train = data[:, 1:2]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X_train, y_train, \"bo\")\n",
    "plt.show()\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 2\n",
      "[[ 4.85305166]\n",
      " [ 0.49115562]]\n"
     ]
    }
   ],
   "source": [
    "data_plus_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "data_plus_bias_m, data_plus_bias_n = data_plus_bias.shape\n",
    "print(data_m, data_n)\n",
    "\n",
    "X = tf.constant(data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(y_train.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    print(theta_value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x227e4e7dcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_train, y_train, \"bo\")\n",
    "#plt.plot([0, 60000], [theta_value[1][0], w[0][0] * (60000 / 10000) + theta_value[1][0]])\n",
    "plt.plot([0, 5], [theta_value[0][0],theta_value[1][0]*5+theta_value[0][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Gradient Descent\n",
    "Możemy zminimalizować funkcję kosztu gradientowo wykorzystując gradient:\n",
    "```python\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.75443\n",
      "Epoch 100 MSE = 0.632222\n",
      "Epoch 200 MSE = 0.57278\n",
      "Epoch 300 MSE = 0.558501\n",
      "Epoch 400 MSE = 0.549069\n",
      "Epoch 500 MSE = 0.542288\n",
      "Epoch 600 MSE = 0.537379\n",
      "Epoch 700 MSE = 0.533822\n",
      "Epoch 800 MSE = 0.531243\n",
      "Epoch 900 MSE = 0.529371\n",
      "[[  2.06855226e+00]\n",
      " [  7.74078071e-01]\n",
      " [  1.31192386e-01]\n",
      " [ -1.17845096e-01]\n",
      " [  1.64778158e-01]\n",
      " [  7.44080753e-04]\n",
      " [ -3.91945168e-02]\n",
      " [ -8.61356616e-01]\n",
      " [ -8.23479712e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Zad.\n",
    "Wykonaj regresje powyższym sposobem na danych life_satisfaction.csv oraz narysuj wykres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 0 MSE = 19.6125\n",
      "Epoch 100 MSE = 1.35452\n",
      "Epoch 200 MSE = 0.83155\n",
      "Epoch 300 MSE = 0.541586\n",
      "Epoch 400 MSE = 0.380816\n",
      "Epoch 500 MSE = 0.291677\n",
      "Epoch 600 MSE = 0.242254\n",
      "Epoch 700 MSE = 0.214851\n",
      "Epoch 800 MSE = 0.199657\n",
      "Epoch 900 MSE = 0.191233\n",
      "[[ 4.66054201]\n",
      " [ 0.54031867]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy też użyć gradientu wyliczonego za pomocą automatycznego różniczkowania\n",
    "```python\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.75443\n",
      "Epoch 100 MSE = 0.632222\n",
      "Epoch 200 MSE = 0.57278\n",
      "Epoch 300 MSE = 0.558501\n",
      "Epoch 400 MSE = 0.549069\n",
      "Epoch 500 MSE = 0.542288\n",
      "Epoch 600 MSE = 0.537379\n",
      "Epoch 700 MSE = 0.533822\n",
      "Epoch 800 MSE = 0.531243\n",
      "Epoch 900 MSE = 0.529371\n",
      "Best theta:\n",
      "[[  2.06855249e+00]\n",
      " [  7.74078071e-01]\n",
      " [  1.31192386e-01]\n",
      " [ -1.17845066e-01]\n",
      " [  1.64778143e-01]\n",
      " [  7.44078017e-04]\n",
      " [ -3.91945094e-02]\n",
      " [ -8.61356676e-01]\n",
      " [ -8.23479772e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Wykonaj regresje powyższym sposobem na danych life_satisfaction.csv oraz narysuj wykres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 0 MSE = 19.6125\n",
      "Epoch 100 MSE = 1.35452\n",
      "Epoch 200 MSE = 0.83155\n",
      "Epoch 300 MSE = 0.541586\n",
      "Epoch 400 MSE = 0.380816\n",
      "Epoch 500 MSE = 0.291677\n",
      "Epoch 600 MSE = 0.242254\n",
      "Epoch 700 MSE = 0.214851\n",
      "Epoch 800 MSE = 0.199657\n",
      "Epoch 900 MSE = 0.191233\n",
      "[[ 4.66054201]\n",
      " [ 0.54031867]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ciekwaostka\n",
    "\n",
    "Jak można znaleźć pochodne cząstkowe poniższej funkcji w odniesieniu do a i b?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21253923284754914"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_func(a, b):\n",
    "    z = 0\n",
    "    for i in range(100):\n",
    "        z = a * np.cos(z + i) + z * np.sin(b - i)\n",
    "    return z\n",
    "\n",
    "my_func(0.2, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.212537\n",
      "[-1.1388494, 0.19671395]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "a = tf.Variable(0.2, name=\"a\")\n",
    "b = tf.Variable(0.3, name=\"b\")\n",
    "z = tf.constant(0.0, name=\"z0\")\n",
    "for i in range(100):\n",
    "    z = a * tf.cos(z + i) + z * tf.sin(b - i)\n",
    "\n",
    "grads = tf.gradients(z, [a, b])\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(z.eval())\n",
    "    print(sess.run(grads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Optimizer\n",
    "\n",
    "Możemy również użyć wbudowanej funkcji do optymalizacji\n",
    "\n",
    "```python\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.75443\n",
      "Epoch 100 MSE = 0.632222\n",
      "Epoch 200 MSE = 0.57278\n",
      "Epoch 300 MSE = 0.558501\n",
      "Epoch 400 MSE = 0.549069\n",
      "Epoch 500 MSE = 0.542288\n",
      "Epoch 600 MSE = 0.537379\n",
      "Epoch 700 MSE = 0.533822\n",
      "Epoch 800 MSE = 0.531243\n",
      "Epoch 900 MSE = 0.529371\n",
      "Best theta:\n",
      "[[  2.06855249e+00]\n",
      " [  7.74078071e-01]\n",
      " [  1.31192386e-01]\n",
      " [ -1.17845066e-01]\n",
      " [  1.64778143e-01]\n",
      " [  7.44078017e-04]\n",
      " [ -3.91945094e-02]\n",
      " [ -8.61356676e-01]\n",
      " [ -8.23479772e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest wiele różnych metod optymalizacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.75443\n",
      "Epoch 100 MSE = 0.527316\n",
      "Epoch 200 MSE = 0.524414\n",
      "Epoch 300 MSE = 0.524328\n",
      "Epoch 400 MSE = 0.524322\n",
      "Epoch 500 MSE = 0.524321\n",
      "Epoch 600 MSE = 0.524321\n",
      "Epoch 700 MSE = 0.52432\n",
      "Epoch 800 MSE = 0.524321\n",
      "Epoch 900 MSE = 0.524321\n",
      "Best theta:\n",
      "[[ 2.06855798]\n",
      " [ 0.82961673]\n",
      " [ 0.11875112]\n",
      " [-0.26552212]\n",
      " [ 0.30569226]\n",
      " [-0.00450316]\n",
      " [-0.03932616]\n",
      " [-0.89989167]\n",
      " [-0.87054664]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Zad.\n",
    "Wykonaj regresje powyższym sposobem na danych life_satisfaction.csv oraz narysuj wykres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 19.6125\n",
      "Epoch 100 MSE = 0.181109\n",
      "Epoch 200 MSE = 0.18075\n",
      "Epoch 300 MSE = 0.18075\n",
      "Epoch 400 MSE = 0.18075\n",
      "Epoch 500 MSE = 0.18075\n",
      "Epoch 600 MSE = 0.18075\n",
      "Epoch 700 MSE = 0.18075\n",
      "Epoch 800 MSE = 0.18075\n",
      "Epoch 900 MSE = 0.18075\n",
      "Best theta:\n",
      "[[ 4.853055 ]\n",
      " [ 0.4911539]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warstwa typu placeholder\n",
    "Warstwa typu placeholder pozwala na dynamiczne dostarczanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  7.  8.]]\n",
      "[[  9.  10.  11.]\n",
      " [ 12.  13.  14.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
    "\n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "W naszym przypadku mamy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 0.502484\n",
      "Epoch 10 MSE = 0.561448\n",
      "Epoch 20 MSE = 0.552032\n",
      "Epoch 30 MSE = 0.590603\n",
      "Epoch 40 MSE = 0.344873\n",
      "Epoch 50 MSE = 0.440544\n",
      "Epoch 60 MSE = 0.548122\n",
      "Epoch 70 MSE = 0.448121\n",
      "Epoch 80 MSE = 0.585612\n",
      "Epoch 90 MSE = 0.386596\n",
      "Best theta:\n",
      "[[ 2.0544672 ]\n",
      " [ 0.82970113]\n",
      " [ 0.10713524]\n",
      " [-0.31074819]\n",
      " [ 0.24564511]\n",
      " [-0.00222412]\n",
      " [-0.01061389]\n",
      " [-0.89121586]\n",
      " [-0.87524796]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  \n",
    "    indices = np.random.randint(m, size=batch_size)  \n",
    "    X_batch = housing_data_plus_bias[indices] \n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] \n",
    "    return X_batch, y_batch\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", sess.run( mse, feed_dict={X: X_batch, y: y_batch}) )   \n",
    "\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    \n",
    "print(\"Best theta:\")\n",
    "print(best_theta)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    best_theta_restored = theta.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0544672 ]\n",
      " [ 0.82970113]\n",
      " [ 0.10713524]\n",
      " [-0.31074819]\n",
      " [ 0.24564511]\n",
      " [-0.00222412]\n",
      " [-0.01061389]\n",
      " [-0.89121586]\n",
      " [-0.87524796]]\n"
     ]
    }
   ],
   "source": [
    "print(best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Proszę wykonać regresję za pomocą sieci neuronowej złożonej z dwóch warstw fully connected z warstwą aktywacji relu na poniższych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_fun = lambda X: np.cos(1.5 * np.pi * X)\n",
    "n_samples=200\n",
    "X_train = np.sort(np.random.rand(n_samples))\n",
    "y_train = true_fun(X_train) + np.random.randn(n_samples) * 0.1\n",
    "X_train=np.vstack(X_train)\n",
    "y_train=np.vstack(y_train)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X_train, y_train, \"bo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 1\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, n_outputs), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystamy sieć typu fully_connected z funkcją aktywacji relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"weights\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"biases\")\n",
    "        z = tf.matmul(X, W) + b\n",
    "        if activation==\"relu\":\n",
    "            return tf.nn.relu(z)\n",
    "        else:\n",
    "            return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, \"hidden1\", activation=\"relu\")\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, \"hidden2\", activation=\"relu\")\n",
    "    y_pred = neuron_layer(hidden2, n_outputs, \"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    error = y_pred - y\n",
    "    loss = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "        \n",
    "learning_rate = 0.001\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 mse: 0.23533\n",
      "Epoch 100 mse: 0.182371\n",
      "Epoch 200 mse: 0.195548\n",
      "Epoch 300 mse: 0.119697\n",
      "Epoch 400 mse: 0.148003\n",
      "Epoch 500 mse: 0.100984\n",
      "Epoch 600 mse: 0.131563\n",
      "Epoch 700 mse: 0.0646537\n",
      "Epoch 800 mse: 0.0647853\n",
      "Epoch 900 mse: 0.0867684\n",
      "Epoch 1000 mse: 0.0649976\n",
      "Epoch 1100 mse: 0.0633444\n",
      "Epoch 1200 mse: 0.0416062\n",
      "Epoch 1300 mse: 0.0299712\n",
      "Epoch 1400 mse: 0.0370246\n",
      "Epoch 1500 mse: 0.0337202\n",
      "Epoch 1600 mse: 0.0139638\n",
      "Epoch 1700 mse: 0.0168709\n",
      "Epoch 1800 mse: 0.0155166\n",
      "Epoch 1900 mse: 0.0155002\n",
      "Epoch 2000 mse: 0.0254837\n",
      "Epoch 2100 mse: 0.00921041\n",
      "Epoch 2200 mse: 0.0141502\n",
      "Epoch 2300 mse: 0.0154058\n",
      "Epoch 2400 mse: 0.0117753\n",
      "Epoch 2500 mse: 0.0097913\n",
      "Epoch 2600 mse: 0.0141501\n",
      "Epoch 2700 mse: 0.0120437\n",
      "Epoch 2800 mse: 0.00835322\n",
      "Epoch 2900 mse: 0.00738988\n",
      "Epoch 3000 mse: 0.0133471\n",
      "Epoch 3100 mse: 0.0155926\n",
      "Epoch 3200 mse: 0.0101292\n",
      "Epoch 3300 mse: 0.012084\n",
      "Epoch 3400 mse: 0.01009\n",
      "Epoch 3500 mse: 0.0128957\n",
      "Epoch 3600 mse: 0.0118116\n",
      "Epoch 3700 mse: 0.0130931\n",
      "Epoch 3800 mse: 0.00851442\n",
      "Epoch 3900 mse: 0.00931895\n"
     ]
    }
   ],
   "source": [
    "x_dom = np.vstack(np.arange(0,1,0.01))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 4000\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(len(X_train) / batch_size))\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size, X,  y):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(X.shape[0], size=batch_size)  # not shown\n",
    "    X_batch = X[indices] # not shown\n",
    "    y_batch = y[indices] # not shown\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size, X_train, y_train)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 100 == 0:\n",
    "            acc_train = loss.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            print(\"Epoch\", epoch, \"mse:\", acc_train)#, \"Val accuracy:\", acc_val)\n",
    "    x_dom_pred = y_pred.eval(feed_dict={X: x_dom})\n",
    "    #save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X_train, y_train, \"bo\")\n",
    "plt.plot(x_dom, x_dom_pred, color='red',linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Proszę wykonać regresję za pomocą sieci neuronowej złożonej z dwóch warstw fully connected z warstwą aktywacji relu na danych \n",
    "housing ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
